seed: 1
record_video: yes

environment:
  render: True
# just testing commenting
  num_envs: 100
  # eval_every_n: 200 # original
  eval_every_n: 100
  num_threads: 30 # this is not used for anything in the code
  simulation_dt: 0.002 # seconds
  control_dt: 0.01 # seconds
  max_time: 4.0 # seconds
  # reward:
  #   forwardVel:
  #     coeff: 0.3
  #   torque:
  #     coeff: -4e-5
  # reward:
  #   forwardVel:
  #     coeff: 0.5
  #   torque:
  #     coeff: -4e-7
  #   lateralVel:
  #     coeff: -1e-4
  
  # reward:
  #   forwardVel:
  #     coeff: 0.5
  #   torque:
  #     coeff: -4e-7
  #   lateralVel:
  #     coeff: -1e-4
  reward:
    vel_body_tracking_error:
      coeff: 2.0
    vel_ang_tracking_error:
      coeff: 1.0
    torque:
      coeff: -4e-7
    vel_body_lin_z:
      coeff: -2.0
    vel_ang_xy:
      coeff: -0.05
    height_body_tracking_error:
      coeff: 0.75
    pos_hips_des:
      coeff: -1.0
    action_rate:
      coeff: -0.001 # this kind of worked...
    pos_joint_off_limits:
      coeff: -0.0


# # amarco
# policy:
#   action_std: 0.01 # q_des = q_init + action_std * action

trial: "hole"

architecture:
  policy_net: [128, 128]
  value_net: [128, 128]
